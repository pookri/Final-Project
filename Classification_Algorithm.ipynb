{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_curve,accuracy_score\n",
    "import category_encoders as ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=pd.read_csv(\"Traindata.csv\")\n",
    "X = traindata.drop(['class'], axis=1)\n",
    "y = traindata['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(X_train,X_test):\n",
    "    encoder = ce.OrdinalEncoder(cols=['age', 'job', 'marital', 'education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome'])\n",
    "    X_train = encoder.fit_transform(X_train)\n",
    "    X_test = encoder.transform(X_test)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTree(clf,X_train):\n",
    "    cls=['yes','no']\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                              feature_names=X_train.columns, \n",
    "                              class_names=cls,\n",
    "                              filled=True, rounded=True,  \n",
    "                              special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_png('Decisiontree.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOutput(X_test_original,prediction,algoNum):\n",
    "    X_test_original['Will subscribe a term deposit(yes/no)']=prediction\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.colheader_justify', 'center')\n",
    "    pd.set_option('display.precision', 3)\n",
    "    if(algoNum==1):\n",
    "        X_test_original.to_csv(\"DecisionTreeOutput.csv\",index=False)\n",
    "    else:\n",
    "        X_test_original.to_csv(\"NavieBayesOutput.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHeatMap(cm,algoNum):\n",
    "    \n",
    "    cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "    if(algoNum==1):\n",
    "        result_path = 'DecisionTree_HeatMap.png'\n",
    "    else:\n",
    "        result_path='NavieBayes_HeatMap.png'\n",
    "    plt.savefig(result_path, dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelEvalution(y_test,prediction,algoNum):\n",
    "    cm=confusion_matrix(y_test,prediction)\n",
    "    TP = cm[0,0]\n",
    "    TN = cm[1,1]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "    classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "    precision = TP / float(TP + FP)\n",
    "    recall = TP / float(TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    true_positive_rate = TP / float(TP + FN)\n",
    "    false_positive_rate = FP / float(FP + TN)\n",
    "    true_negative_rate=TN / float(TN + FP)\n",
    "    false_negative_rate=FN / float(FN + TP)\n",
    "    specificity = TN / (TN + FP)\n",
    "    if(algoNum==1):\n",
    "        printHeatMap(cm,1)\n",
    "    else:\n",
    "        printHeatMap(cm,2)\n",
    "    return [round(classification_accuracy,3),round(classification_error,3),precision,recall,f1_score,true_positive_rate,false_positive_rate,true_negative_rate,false_negative_rate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation_Score(clf,X_train,y_train):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv = 10, scoring='accuracy')\n",
    "    cross_validation_score=scores.mean()\n",
    "    return round(scores.mean(),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decisiontree():\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.8, test_size=0.2, random_state=10)\n",
    "    X_test_original=X_test.copy(deep=False)\n",
    "    X_train_original=X_train.copy(deep=False)\n",
    "    X_train,X_test=encoding(X_train,X_test)\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",max_depth=3,random_state=0) #max_depth is maximum number of levels in the tree\n",
    "    clf.fit(X_train,y_train)\n",
    "    printTree(clf,X_train)\n",
    "    prediction=clf.predict(X_test)\n",
    "    printOutput(X_test_original,prediction,1)\n",
    "    evalList=ModelEvalution(y_test,prediction,1)\n",
    "    evalList.append(crossValidation_Score(clf,X_train,y_train))\n",
    "    return evalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krupal\\anaconda3\\envs\\dtree\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead.\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "dtlist=Decisiontree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes():\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.8, test_size=0.2, random_state=10)\n",
    "    X_test_original=X_test.copy(deep=False)\n",
    "    X_train_original=X_train.copy(deep=False)\n",
    "    X_train,X_test=encoding(X_train,X_test)\n",
    "    nv = GaussianNB()\n",
    "    nv.fit(X_train, y_train)\n",
    "    y_pred = nv.predict(X_test)\n",
    "    printOutput(X_test_original,y_pred,2)\n",
    "    evalList=ModelEvalution(y_test,y_pred,2)\n",
    "    evalList.append(crossValidation_Score(nv,X_train,y_train))\n",
    "    return evalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krupal\\anaconda3\\envs\\dtree\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead.\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "nbList=NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Decision Tree Algorithm  Navie Bayes Algorithm\n",
      "Classification Accuracy Score           0.883                   0.813        \n",
      "Classification Error                    0.117                   0.187        \n",
      "Precision                               0.985                   0.876        \n",
      "Recall                                  0.893                   0.909        \n",
      "F1 Score                                0.937                   0.892        \n",
      "True Positive Rate                      0.893                   0.909        \n",
      "False Positive Rate                     0.444                   0.717        \n",
      "True Negative Rate                      0.556                   0.283        \n",
      "False Negative Rate                     0.107                   0.091        \n",
      "Cross Validation Score                  0.893                   0.823        \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {'Decision Tree Algorithm':dtlist,'Navie Bayes Algorithm':nbList}\n",
    "headers=[\"Classification Accuracy Score\",\"Classification Error\", \"Precision\", \"Recall\", \"F1 Score\",\"True Positive Rate\",\"False Positive Rate\",\"True Negative Rate\",\"False Negative Rate\",\"Cross Validation Score\"] \n",
    "print(pd.DataFrame(data, headers))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5288d29ac42d8e8d2c0fc1c039d1901c9162323c060aa9d5426e55416be85c12"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dtree')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
